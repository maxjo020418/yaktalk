"""
ë²•ë ¹ ì •ë³´ API í˜¸ì¶œ ë° ChromaDB ì €ì¥ ëª¨ë“ˆ
"""

import os
import sys
import requests
import re
from pathlib import Path
from typing import Dict, List, Optional, Any
from dataclasses import dataclass

# ëª¨ë“ˆ ê²½ë¡œ ì¶”ê°€ (ì§ì ‘ ì‹¤í–‰ ì‹œ)
sys.path.append(str(Path(__file__).parent.parent))

from langchain_core.tools import tool
from langchain_core.documents import Document
from langchain_community.vectorstores import Chroma
from langchain.text_splitter import RecursiveCharacterTextSplitter
import chromadb
from chromadb.config import Settings

from utils.custom_embeddings import get_law_embeddings
from utils.get_env import OLLAMA_SERVER_URL, OPEN_LAW_GO_ID


@dataclass
class LawConfig:
    """ë²•ë ¹ API ì„¤ì •"""
    api_base_url: str = "http://www.law.go.kr/DRF/lawService.do"
    search_base_url: str = "http://www.law.go.kr/DRF/lawSearch.do"
    chunk_size: int = 1024
    chunk_overlap: int = 100
    max_articles: int = 50
    search_threshold: int = 2
    timeout: int = 10


@dataclass
class ArticleInfo:
    """ì¡°ë¬¸ ì •ë³´"""
    jo: str = ''
    hang: str = ''
    ho: str = ''
    
    def format_reference(self, law_name: str) -> str:
        """ì¡°í•­ ì •ë³´ë¥¼ ì½ê¸° ì‰¬ìš´ í˜•íƒœë¡œ í¬ë§·"""
        reference = law_name
        if self.jo:
            reference += f" ì œ{self.jo}ì¡°"
        if self.hang:
            reference += f" ì œ{self.hang}í•­"
        if self.ho:
            reference += f" ì œ{self.ho}í˜¸"
        return reference


class LawAPIClient:
    """ë²•ë ¹ API í´ë¼ì´ì–¸íŠ¸"""
    
    def __init__(self, config: LawConfig | None = None):
        self.config = config or LawConfig()
        self.api_key = OPEN_LAW_GO_ID
    
    def search_laws(self, query: str) -> Optional[Dict]:
        """ë²•ë ¹ ê²€ìƒ‰"""
        params = {
            'OC': self.api_key,
            'target': 'law',
            'type': 'JSON',
            'query': query,
            'display': '10'
        }
        
        return self._make_request(self.config.search_base_url, params)
    
    def get_law_by_id(self, law_id: str) -> Optional[Dict]:
        """ë²•ë ¹ IDë¡œ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
        params = {
            'OC': self.api_key,
            'target': 'law',
            'type': 'JSON',
            'ID': law_id
        }
        
        return self._make_request(self.config.api_base_url, params)
    
    def get_law_by_mst(self, mst: str) -> Optional[Dict]:
        """ë²•ë ¹ ì¼ë ¨ë²ˆí˜¸ë¡œ ìƒì„¸ ì •ë³´ ì¡°íšŒ"""
        params = {
            'OC': self.api_key,
            'target': 'law',
            'type': 'JSON',
            'MST': mst
        }
        
        return self._make_request(self.config.api_base_url, params)
    
    def _make_request(self, url: str, params: Dict) -> Optional[Dict]:
        """API ìš”ì²­ ì‹¤í–‰"""
        try:
            response = requests.get(url, params=params, timeout=self.config.timeout)
            if response.status_code == 200:
                return response.json()
        except Exception as e:
            print(f"API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
        return None


class LawDocumentProcessor:
    """ë²•ë ¹ ë¬¸ì„œ ì²˜ë¦¬ê¸°"""
    
    def __init__(self, config: LawConfig | None = None):
        self.config = config or LawConfig()
    
    def parse_article_number(self, article_num: str) -> ArticleInfo:
        """ì¡°ë¬¸ë²ˆí˜¸ë¥¼ íŒŒì‹±í•˜ì—¬ ì¡°/í•­/í˜¸ ì •ë³´ ì¶”ì¶œ"""
        if not article_num:
            return ArticleInfo()
        
        jo_match = re.search(r'ì œ(\d+)ì¡°', article_num)
        hang_match = re.search(r'ì œ(\d+)í•­', article_num)
        ho_match = re.search(r'ì œ(\d+)í˜¸', article_num)
        
        return ArticleInfo(
            jo=jo_match.group(1) if jo_match else '',
            hang=hang_match.group(1) if hang_match else '',
            ho=ho_match.group(1) if ho_match else ''
        )
    
    def create_law_documents(self, law_data: Dict) -> List[Document]:
        """ë²•ë ¹ ë°ì´í„°ë¥¼ Document ê°ì²´ë¡œ ë³€í™˜"""
        documents = []
        
        if 'ë²•ë ¹' not in law_data:
            return documents
            
        law_info = law_data['ë²•ë ¹']
        
        # ê¸°ë³¸ ì •ë³´ ë¬¸ì„œ ìƒì„±
        basic_info = self._create_basic_info(law_info)
        documents.append(basic_info)
        
        # ì¡°ë¬¸ ì •ë³´ ë¬¸ì„œ ìƒì„±
        article_docs = self._create_article_documents(law_info)
        documents.extend(article_docs)
        
        return documents
    
    def _create_basic_info(self, law_info: Dict) -> Document:
        """ë²•ë ¹ ê¸°ë³¸ ì •ë³´ ë¬¸ì„œ ìƒì„±"""
        content = f"""
        ë²•ë ¹ëª…: {law_info.get('ë²•ë ¹ëª…_í•œê¸€', 'N/A')}
        ë²•ë ¹ID: {law_info.get('ë²•ë ¹ID', 'N/A')}
        ê³µí¬ì¼ì: {law_info.get('ê³µí¬ì¼ì', 'N/A')}
        ì‹œí–‰ì¼ì: {law_info.get('ì‹œí–‰ì¼ì', 'N/A')}
        ì†Œê´€ë¶€ì²˜: {law_info.get('ì†Œê´€ë¶€ì²˜ëª…', 'N/A')}
        """
        
        return Document(
            page_content=content.strip(),
            metadata={
                'type': 'law_basic',
                'law_id': law_info.get('ë²•ë ¹ID', ''),
                'law_name': law_info.get('ë²•ë ¹ëª…_í•œê¸€', '')
            }
        )
    
    def _create_article_documents(self, law_info: Dict) -> List[Document]:
        """ì¡°ë¬¸ ì •ë³´ ë¬¸ì„œë“¤ ìƒì„±"""
        documents = []
        
        if 'ì¡°ë¬¸' not in law_info:
            return documents
            
        articles = law_info.get('ì¡°ë¬¸', [])
        if isinstance(articles, dict):
            articles = [articles]
        
        for article in articles[:self.config.max_articles]:
            if isinstance(article, dict):
                doc = self._create_single_article_document(article, law_info)
                if doc:
                    documents.append(doc)
        
        return documents
    
    def _create_single_article_document(self, article: Dict, law_info: Dict) -> Optional[Document]:
        """ë‹¨ì¼ ì¡°ë¬¸ ë¬¸ì„œ ìƒì„±"""
        article_num = article.get('ì¡°ë¬¸ë²ˆí˜¸', '')
        article_title = article.get('ì¡°ë¬¸ì œëª©', '')
        article_content = article.get('ì¡°ë¬¸ë‚´ìš©', '')
        
        if not article_content:
            return None
        
        article_info = self.parse_article_number(article_num)
        
        content = f"""
        ì¡°ë¬¸ë²ˆí˜¸: {article_num}
        ì¡°ë¬¸ì œëª©: {article_title}
        ì¡°ë¬¸ë‚´ìš©: {article_content}
        """.strip()
        
        return Document(
            page_content=content,
            metadata={
                'type': 'law_article',
                'law_id': law_info.get('ë²•ë ¹ID', ''),
                'law_name': law_info.get('ë²•ë ¹ëª…_í•œê¸€', ''),
                'article_title': article_title,
                'article_number': article_num,
                'jo': article_info.jo,
                'hang': article_info.hang,
                'ho': article_info.ho
            }
        )


class LawVectorStore:
    """ë²•ë ¹ ë²¡í„° ìŠ¤í† ì–´ ê´€ë¦¬"""
    
    def __init__(self, config: LawConfig | None = None):
        self.config = config or LawConfig()
        self.processor = LawDocumentProcessor(config)
        self._initialize()
    
    def _initialize(self):
        """ë²¡í„°ìŠ¤í† ì–´ ì´ˆê¸°í™”"""
        embeddings = get_law_embeddings(OLLAMA_SERVER_URL, "nomic-embed-text")
        
        persist_directory = Path(__file__).parent.parent / "database" / "law_chroma_db"
        persist_directory.mkdir(parents=True, exist_ok=True)
        
        client = chromadb.PersistentClient(
            path=str(persist_directory),
            settings=Settings(anonymized_telemetry=False)
        )
        
        self.vectorstore = Chroma(
            client=client,
            collection_name="law_documents",
            embedding_function=embeddings,
            persist_directory=str(persist_directory)
        )

        assert self.vectorstore is not None, f"Vectorstore must be initialized"
        print(f"âœ… ë²•ë ¹ ChromaDB ì´ˆê¸°í™” ì™„ë£Œ: {persist_directory}")
    
    def add_law_data(self, law_data: Dict) -> int:
        """ë²•ë ¹ ë°ì´í„°ë¥¼ ë²¡í„°ìŠ¤í† ì–´ì— ì¶”ê°€"""
        documents = self.processor.create_law_documents(law_data)
        
        if not documents:
            return 0
        
        # í…ìŠ¤íŠ¸ ë¶„í• 
        text_splitter = RecursiveCharacterTextSplitter(
            chunk_size=self.config.chunk_size,
            chunk_overlap=self.config.chunk_overlap,
            separators=["\n\n", "\n", ".", " ", ""]
        )
        
        splits = text_splitter.split_documents(documents)
        
        if splits:
            assert self.vectorstore is not None, "Vectorstore must be initialized before adding documents"
            self.vectorstore.add_documents(splits)
            print(f"âœ… {len(splits)}ê°œì˜ ë²•ë ¹ ì²­í¬ ì¶”ê°€ ì™„ë£Œ")
        
        return len(splits)
    
    def search(self, query: str, k: int = 5) -> List[Document]:
        """ë²¡í„°ìŠ¤í† ì–´ì—ì„œ ê²€ìƒ‰"""
        assert self.vectorstore is not None, "Vectorstore must be initialized before searching"
        retriever = self.vectorstore.as_retriever(
            search_type="similarity",
            search_kwargs={"k": k}
        )
        return retriever.invoke(query) or []
    
    def is_sufficient_result(self, docs: List[Document], query: str) -> bool:
        """ê²€ìƒ‰ ê²°ê³¼ê°€ ì¶©ë¶„í•œì§€ íŒë‹¨"""
        if not docs or len(docs) < self.config.search_threshold:
            return False
        
        query_keywords = set(query.lower().split())
        relevant_count = sum(
            1 for doc in docs 
            if any(keyword in doc.page_content.lower() for keyword in query_keywords)
        )
        
        return relevant_count >= self.config.search_threshold


class LawService:
    """ë²•ë ¹ ì„œë¹„ìŠ¤ ë©”ì¸ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self.config = LawConfig()
        self.api_client = LawAPIClient(self.config)
        self.vector_store = LawVectorStore(self.config)
        self.processor = LawDocumentProcessor(self.config)
        self.cache: Dict[str, Any] = {}
    
    def search_laws(self, query: str) -> str:
        """ë²•ë ¹ ê²€ìƒ‰ ë©”ì¸ ë¡œì§"""
        print(f"ğŸ” ë²•ë ¹ ê²€ìƒ‰: '{query}'")
        
        # 1ë‹¨ê³„: ChromaDBì—ì„œ ê¸°ì¡´ ë²•ë ¹ ê²€ìƒ‰
        existing_docs = self.vector_store.search(query)
        
        # 2ë‹¨ê³„: ê²€ìƒ‰ ê²°ê³¼ê°€ ì¶©ë¶„í•œì§€ í™•ì¸
        if self.vector_store.is_sufficient_result(existing_docs, query):
            print("âœ… ChromaDBì—ì„œ ì¶©ë¶„í•œ ë²•ë ¹ ì •ë³´ ë°œê²¬")
            return self._format_results(existing_docs, "ê·¼ê±°ë²•ë ¹")
        
        # 3ë‹¨ê³„: API í˜¸ì¶œë¡œ ìƒˆë¡œìš´ ë²•ë ¹ ê°€ì ¸ì˜¤ê¸°
        print("âš¡ ChromaDBì— ê´€ë ¨ ë²•ë ¹ì´ ë¶€ì¡±í•˜ì—¬ API í˜¸ì¶œ ì¤‘...")
        
        law_data = self._fetch_law_data_by_query(query)
        
        if law_data:
            print("âœ… ìƒˆë¡œìš´ ë²•ë ¹ ë°ì´í„° íšë“, ChromaDBì— ì €ì¥ ì¤‘...")
            
            # ìºì‹œ ì €ì¥
            cache_key = query[:50]
            self.cache[cache_key] = law_data
            
            # ë²¡í„°ìŠ¤í† ì–´ì— ì¶”ê°€
            self.vector_store.add_law_data(law_data)
            
            # ì—…ë°ì´íŠ¸ëœ DBì—ì„œ ë‹¤ì‹œ ê²€ìƒ‰
            updated_docs = self.vector_store.search(query)
            if updated_docs:
                return self._format_results(updated_docs, "ìƒˆë¡œ ì¶”ê°€ëœ ê·¼ê±°ë²•ë ¹")
        
        # ìµœì¢… ë‹¨ê³„: ê¸°ì¡´ ê²°ê³¼ë¼ë„ ë°˜í™˜
        if existing_docs:
            print("âš ï¸ ìƒˆ ë²•ë ¹ ì¶”ê°€ ì‹¤íŒ¨, ê¸°ì¡´ ê²°ê³¼ ë°˜í™˜")
            return self._format_results(existing_docs[:3], "ê¸°ì¡´ ê·¼ê±°ë²•ë ¹")
        
        return "ê´€ë ¨ ë²•ë ¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

    def load_law_by_id(self, law_id: str | None = None, mst: str | None = None) -> str:
        """íŠ¹ì • ë²•ë ¹ IDë¡œ ë²•ë ¹ ì •ë³´ ë¡œë“œ"""
        law_data = None
        
        if law_id:
            law_data = self.api_client.get_law_by_id(law_id)
        elif mst:
            law_data = self.api_client.get_law_by_mst(mst)
        
        if law_data and 'ë²•ë ¹' in law_data:
            law_info = law_data['ë²•ë ¹']
            self.vector_store.add_law_data(law_data)

            return f"ë²•ë ¹ëª…: {law_info.get('ë²•ë ¹ëª…_í•œê¸€', 'N/A')}" \
                   f"\në²•ë ¹ID: {law_info.get('ë²•ë ¹ID', 'N/A')}" \
                   f"\nê³µí¬ì¼ì: {law_info.get('ê³µí¬ì¼ì', 'N/A')}" \
                   f"\nì‹œí–‰ì¼ì: {law_info.get('ì‹œí–‰ì¼ì', 'N/A')}" \
                   f"\nì†Œê´€ë¶€ì²˜: {law_info.get('ì†Œê´€ë¶€ì²˜ëª…', 'N/A')}" \
                   f"\nì¡°ë¬¸ ìˆ˜: {len(law_info.get('ì¡°ë¬¸', []))}ê°œ" \
                   f"\në²•ë ¹ ì •ë³´ê°€ ë²¡í„°ìŠ¤í† ì–´ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.".strip()
        
        return "ë²•ë ¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    def _fetch_law_data_by_query(self, query: str) -> Optional[Dict]:
        """ì¿¼ë¦¬ë¡œ ë²•ë ¹ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°"""
        # ë¨¼ì € ê²€ìƒ‰ìœ¼ë¡œ ë²•ë ¹ ì°¾ê¸°
        search_result = self.api_client.search_laws(query)
        
        if search_result and 'law' in search_result:
            laws = search_result.get('law', [])
            if laws:
                first_law = laws[0]
                law_id = first_law.get('ë²•ë ¹ID')
                if law_id:
                    # ìƒì„¸ ì •ë³´ ê°€ì ¸ì˜¤ê¸°
                    return self.api_client.get_law_by_id(law_id)
        
        return None
    
    def _format_results(self, docs: List[Document], prefix: str) -> str:
        """ê²€ìƒ‰ ê²°ê³¼ë¥¼ í¬ë§·íŒ…"""
        results = []
        
        for i, doc in enumerate(docs[:5], 1):
            # ì¡°í•­ ì •ë³´ í¬ë§·íŒ…
            article_info = ArticleInfo(
                jo=doc.metadata.get('jo', ''),
                hang=doc.metadata.get('hang', ''),
                ho=doc.metadata.get('ho', '')
            )
            
            law_name = doc.metadata.get('law_name', 'Unknown')
            article_ref = article_info.format_reference(law_name)
            content = doc.page_content[:500]
            
            results.append(f"[{prefix} {i}] {article_ref}\n{content}")
        
        return "\n\n".join(results)


# ì „ì—­ ì„œë¹„ìŠ¤ ì¸ìŠ¤í„´ìŠ¤
_law_service = LawService()


@tool
def search_law_by_query(query: str) -> str:
    """
    Search for legal information and return relevant content.
    
    Args:
        query: Legal-related query to search
    
    Returns:
        Relevant legal information
    """
    return _law_service.search_laws(query)


@tool
def load_law_by_id(law_id: str | None = None, mst: str | None = None) -> str:
    """
    Load legal information by specific law ID or serial number.
    
    Returns:
        Legal information
    """
    return _law_service.load_law_by_id(law_id, mst)


# Export tools
tools = [search_law_by_query, load_law_by_id]